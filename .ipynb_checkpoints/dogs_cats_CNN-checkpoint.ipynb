{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8ceb960",
   "metadata": {
    "id": "a8ceb960"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32b2ac3a",
   "metadata": {
    "id": "32b2ac3a",
    "outputId": "490c7d9e-9781-478e-e4ea-df7253a7048d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 70 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 232 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 164 extraneous bytes before marker 0xd9\n",
      "Warning: unknown JFIF revision number 0.00\n",
      "Corrupt JPEG data: 2232 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 259 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 402 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1408 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 217 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1158 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 104 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 133 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 242 extraneous bytes before marker 0xd9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "datadir=\"assets/animals/PetImages/\"\n",
    "ctgs = ['Dog','Cat']\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for ctg in ctgs:\n",
    "        #make path to get into Cats/Dogs folder\n",
    "        path = os.path.join(datadir,ctg)\n",
    "        label = ctgs.index(ctg)\n",
    "        for img in os.listdir(path):\n",
    "            #read the image from CV2 library, by joining the path and\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "                final_img = cv2.resize(img_arr,(80,80)) #resize the image\n",
    "                training_data.append([final_img,label]) #add the images to data, with the label\n",
    "            except Exception as e:\n",
    "                pass\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c069567c",
   "metadata": {
    "id": "11a5c801",
    "outputId": "6c979419-e00d-4168-c78f-8a392b49b5bc"
   },
   "source": [
    "### FILLING IN DATA INTO FEATURES AND LABELS ARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf1ce652",
   "metadata": {
    "id": "bf1ce652"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f089e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afb7c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle data to allow model to train better\n",
    "shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "767c0849",
   "metadata": {
    "id": "767c0849"
   },
   "outputs": [],
   "source": [
    "for features,labels in training_data:\n",
    "    X.append(features)\n",
    "    y.append(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0321522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bdaf30bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80e551cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68da863",
   "metadata": {},
   "source": [
    "### RESHAPE, CONVERT TO FLOAT, NORMALIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "36ea59c9",
   "metadata": {
    "id": "36ea59c9"
   },
   "outputs": [],
   "source": [
    "X = X.reshape(24946, 80, 80, 1)\n",
    "X = X.astype('float32')\n",
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dd2c54a0",
   "metadata": {
    "id": "dd2c54a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - sklearn\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dd453ecb",
   "metadata": {
    "id": "dd453ecb"
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0869eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:-4000]\n",
    "y_train = y[:-4000]\n",
    "X_test = X[-4000:]\n",
    "y_test = y[-4000:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RXsjylqqQRkm",
   "metadata": {
    "id": "RXsjylqqQRkm"
   },
   "source": [
    "### TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d8047dd4",
   "metadata": {
    "id": "d8047dd4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Activation,Flatten,Dropout,MaxPooling2D,Conv2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "QWKnsbvEQXWb",
   "metadata": {
    "id": "QWKnsbvEQXWb"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128,(3,3),input_shape = (80,80,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units = 2, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "pPNwxDhcQXKW",
   "metadata": {
    "id": "pPNwxDhcQXKW"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "             optimizer='Adam',\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b68976c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 78, 78, 128)       1280      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 78, 78, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 39, 39, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 37, 37, 64)        73792     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 37, 37, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 18, 18, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 20736)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               2654336   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,729,666\n",
      "Trainable params: 2,729,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c4bd78bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x15cf02b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x15cf02b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "491/491 [==============================] - ETA: 0s - loss: 0.6595 - accuracy: 0.6022WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x15db74c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x15db74c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "491/491 [==============================] - 282s 573ms/step - loss: 0.6595 - accuracy: 0.6022 - val_loss: 0.6555 - val_accuracy: 0.6024\n",
      "Epoch 2/3\n",
      "491/491 [==============================] - 281s 572ms/step - loss: 0.5959 - accuracy: 0.6862 - val_loss: 0.5742 - val_accuracy: 0.7069\n",
      "Epoch 3/3\n",
      "491/491 [==============================] - 255s 520ms/step - loss: 0.5248 - accuracy: 0.7408 - val_loss: 0.5385 - val_accuracy: 0.7311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15cec2850>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=32,epochs = 3,validation_split=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T2_YyBO5QxMM",
   "metadata": {
    "id": "T2_YyBO5QxMM"
   },
   "source": [
    "### TESTING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HM2qGJxcQqMx",
   "metadata": {
    "id": "HM2qGJxcQqMx"
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f0db69c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 15s 117ms/step - loss: 0.5232 - accuracy: 0.7405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5231969952583313, 0.7404999732971191]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "Och-nSlkQqJ6",
   "metadata": {
    "id": "Och-nSlkQqJ6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.7328726e-20, 1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_img():\n",
    "    size = 80\n",
    "    img = cv2.imread('assets/dog3.png',cv2.IMREAD_GRAYSCALE)\n",
    "    img_arr = cv2.resize(img, (size,size))\n",
    "    return img_arr.reshape(-1,size,size,1)\n",
    "\n",
    "test_img = prepare_img()\n",
    "test_img = test_img.astype('float32')\n",
    "prediction = model.predict([test_img])\n",
    "prediction\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "MTZPPQ1BQqG8",
   "metadata": {
    "id": "MTZPPQ1BQqG8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 78, 78, 128)       1280      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 78, 78, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 39, 39, 128)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 37, 37, 64)        73792     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 37, 37, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 18, 18, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 20736)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               2654336   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,729,666\n",
      "Trainable params: 2,729,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ea7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dogs/cats - CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
